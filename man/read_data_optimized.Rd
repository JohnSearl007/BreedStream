% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_data_optimized.R
\name{read_data_optimized}
\alias{read_data_optimized}
\title{read_data_optimized}
\usage{
read_data_optimized(
  geno.file,
  kinship.file,
  ploidy,
  sex = NULL,
  matings = "none",
  standardize = FALSE,
  n.core = 4,
  partition = FALSE,
  chunk_size = 1e+05,
  result_file = "matings_results.csv"
)
}
\arguments{
\item{geno.file}{Genotype information for COMA.}

\item{kinship.file}{Kinship matrix for COMA.}

\item{ploidy}{Ploidy of species.}

\item{sex}{Sex arguement for COMA.}

\item{matings}{Matings arguement for COMA.}

\item{standardize}{Should COMA standardize.}

\item{n.core}{The number of cores for parelle processing.}

\item{partition}{Partition arguement for COMA.}

\item{chunk_size}{How many matings pairwise combinations can be handled per core.}

\item{result_file}{Filename for the output.}
}
\value{
Input data object for COMA.
}
\description{
The read_data() function from COMA, presents limitations for large datasets due to the way that it utilizes RAM. The read_data_optimized() function features the same functionality and output as read_data() but breaks the calculation of merit for the desired matings into chunks and writes the intermediary output to disk for better memory allocation.
}
