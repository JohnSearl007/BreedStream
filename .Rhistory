nest <- unlist(nest.terms[[j]])
# Use unite() directly in a chain to avoid redundant selection
df[[name]] <- df %>%
unite(temp_column, all_of(nest), sep = "_") %>%
pull(temp_column)
}
# Use select(-nest) once, instead of inside the loop
df <- df %>% select(-all_of(unlist(nest.terms)))
}
return(df)
}
harvest.master <- function(Location, Design.File, Combine.File, Fixed = c("id_1"), Random, Moisture = 15.5, Bushel = 56, Plot.Length = 22.5,
Row.Spacing = 30, Plot.Rows = 2, nest.terms = NULL, nest.name = NULL) {
H2.columns <- c("Date/Time", "Range", "Row", "Id 1", "Weight (lb)", "Moisture (%)", "Test Weight (lb/bu)", "Quick Note", "Harvest Sequence")
df <- fread(Combine.File) %>%
mutate(env = Location)
# Add missing columns, if any, using `data.table` for speed
missing.columns <- setdiff(H2.columns, colnames(df))
if (length(missing.columns) > 0) {
df[, (missing.columns) := NA]
}
# Select the required columns
H2.columns <- append(H2.columns, "env")
df <- df[, ..H2.columns]
# Ensure column classes match
H2.classes <- c("character", "integer", "integer", "character", "numeric", "numeric", "numeric", "character", "integer")
setDT(df)  # Ensure df is a data.table
for (i in seq_along(H2.classes)) {
set(df, j = i, value = as(df[[i]], H2.classes[i]))
}
# Update model terms (convert to data.frame for dplyr compatibility)
df <- model.terms_update(as.data.frame(df), Design.File, Fixed, Random)
# Convert back to data.table to allow the use of `:=`
setDT(df)
# Expand data if necessary
if (any(is.na(df$row)) || any(is.na(df$range))) {
df <- ExpandData(df)
}
# Yield calculation (vectorized)
df[, Adj_Weight := (weight_lb - (weight_lb * (moisture_percent / 100))) / ((100 - Moisture) / 100)]
df[, Yield := (Adj_Weight / Bushel) / (1 / (43560 / (Plot.Length * (Row.Spacing / 12) * Plot.Rows)))]
# Handle nesting terms
df <- nesting(df, nest.terms = nest.terms, nest.name = nest.name)
# Output the cleaned data
return(clean_names(df))
}
outliers = function(data, trait) {
traits = trait
df = data
for (trait in trait) {
hist(as.numeric(unlist(df[, ..trait])), main = paste0("Histogram of: ",trait), xlab = trait)
exit = "N"
while (!(exit == "Y")) {
upper.bound = as.numeric(readline("Enter the upper bound: "))
lower.bound = as.numeric(readline("Enter the lower bound: "))
temp = subset(df, unlist(df[, ..trait]) >= lower.bound & unlist(df[, ..trait]) <= upper.bound)
hist(as.numeric(unlist(temp[, ..trait])), main = paste0("Histogram of: ",trait), xlab = trait)
exit = as.character(readline("Would you like to exit (Y/N)?: "))
}
upper.cutoff = as.numeric(readline("Enter your final upper cutoff: "))
lower.cutoff = as.numeric(readline("Enter your final lower cutoff: "))
df = subset(df, unlist(df[, ..trait]) >= lower.cutoff & unlist(df[, ..trait]) <= upper.cutoff)
}
df2 = data %>% select(!any_of(traits))
clean = left_join(df2, df)
clean[,"Quick Note"] = NA
return(clean)
}
H.Matrix_Optimized = function(pheno.data, geno.data, pedigree.data, trait, Fixed, Random, blend.lower = 1e-5,
blend.upper = 0.05, ploidy = 2, max.iter = 100, map = TRUE, dominance = FALSE,
workspace = "12Gb", pworkspace = "12Gb", min.minor.allele = 5, fix.eff.marker = NULL,
covariates = NULL, mask = NULL, method = NULL, numCores = 2, weight.vector.length = 2,
non.add = "none", max_global_size = 10e+09) {
# Set the maximum allowed size for globals
options(future.globals.maxSize = max_global_size)
# Set up parallel backend
plan(multisession, workers = numCores)
# Extract effects from the model terms
effects = model.terms(Fixed = Fixed, Random = Random)
# Set ASReml R options
asreml.options(ai.sing = TRUE, workspace = workspace, pworkspace = pworkspace)
# Stage 1: Build the initial model
model <- Stage1(filename = pheno.data, traits = trait, effects = effects, solver = "asreml",
workspace = c(workspace, pworkspace))
# Create a sequence of blending weights to evaluate
w.vec <- seq(blend.lower, blend.upper, length.out = weight.vector.length)
# Function to calculate AIC based on blending weight
optimize_blend <- function(w) {
# Generate the blended genomic relationship matrix (H matrix)
geno <- read_geno(geno.data, ploidy = ploidy, map = map, min.minor.allele = min.minor.allele,
ped = pedigree.data, w = w, dominance = dominance)
# Run Stage 2 for the given H matrix
ans <- Stage2(data = model$blues, vcov = model$vcov, geno = geno, non.add = non.add,
workspace = c(workspace, pworkspace), max.iter = max.iter, pairwise = TRUE,
fix.eff.marker = fix.eff.marker, covariates = covariates)
# Return the AIC value for optimization
return(ans$aic)
}
# Use future_lapply to calculate AICs in parallel
aic_values <- future_lapply(w.vec, optimize_blend)
# Find the optimal blending weight with minimum AIC
optimal_index <- which.min(aic_values)
optimal_weight <- w.vec[optimal_index]
print(paste0("Optimal blending weight: ", optimal_weight))
write.table(optimal_weight, file = "optimal_weight.txt", row.names = F, col.names = F, quote = F)
# Now generate the H matrix using the optimal blending weight
genoH <- read_geno(geno.data, ploidy = ploidy, map = map, min.minor.allele = min.minor.allele,
ped = pedigree.data, w = optimal_weight, dominance = dominance)
# Run Stage 2 again with the optimal H matrix
final_ans <- Stage2(data = model$blues, vcov = model$vcov, geno = genoH, non.add = non.add,
workspace = c(workspace, pworkspace), max.iter = max.iter, pairwise = TRUE,
fix.eff.marker = fix.eff.marker, covariates = covariates)
# Prepare for BLUP estimation
prep <- blup_prep(data = model$blues, vcov = model$vcov, geno = genoH, vars = final_ans$vars,
mask = mask, method = method)
# Return the preparation result
return(prep)
}
plot.coordinates <- function(Field.Map) {
# Read the CSV file
data <- fread(Field.Map, header = FALSE)
# Transpose Data
data = as.matrix(data)
# Determine the measure columns (assumes all columns are measure vars)
measure_vars <- names(data)
# Melt the data specifying the measure vars
melted_data <- melt(data, measure.vars = measure_vars, variable.name = "Column", value.name = "Value", na.rm = TRUE)
# Clarify Columns
colnames(melted_data) = c("range", "row", "plot")
# Remove "V" from row
melted_data$row = gsub("V","",melted_data$row)
# Remove Border and Empty Plots
melted_data = melted_data[!melted_data$plot == "B" & !melted_data$plot == "",]
# Formatting of Data
melted_data$range = as.integer(melted_data$range)
melted_data$row = as.integer(melted_data$row)
melted_data$plot = as.character(melted_data$plot)
return(melted_data)
}
COMA.file.1 = function(prep, gain.data, geno.data, pedigree.data, optimal.weight, ploidy = 2, map = TRUE, min.minor.allele = 5, dominance = FALSE) {
df = gain.data
index.coeff <- df$table$index
names(index.coeff) <- df$table$trait
geno = read_geno(geno.data, ploidy = ploidy, map = map, min.minor.allele = min.minor.allele, ped = pedigree.data,
w = optimal.weight, dominance = dominance)
add.effects = blup(data = prep, geno, what = "AM", index.coeff = index.coeff) %>%
rename(add = effect)
marker.effects = if (dominance) {
dom.effects = blup(data = prep, geno, what = "DM", index.coeff = index.coeff) %>%
rename(dom = effect)
left_join(add.effects, dom.effects)
} else {
add.effects
}
marker.effects = marker.effects %>% select(!any_of(c("chrom", "position")))
# Columns of Interest & Add Allele Dosage Information
dosage = fread(geno.data) %>%
select(!any_of(c("chrom", "position"))) %>%
{ .[, 2:ncol(.)] * (ploidy / max(.[, 2:ncol(.)])) } # Correcting if not coded correctly
dosage = cbind(marker = add.effects$marker, dosage)
output = left_join(marker.effects, dosage)
write.csv(output, file = "COMA_file_1.csv", quote = F, row.names = F)
return(output)
}
COMA.file.2 = function(pedigree.data, ploidy = 2) {
pedigree.data[is.na(pedigree.data)] <- 0
A = Amatrix(data = pedigree.data, ploidy = ploidy)
write.csv(A, file = "COMA_file_2.csv", quote = F)
return(A)
}
PRISM.Pedigree = function(data) {
# Read the data
data <- fread(data)
# Clean and prepare data
data <- data %>%
filter(!grepl(" X ", Pedigree)) %>%
select(Pedigree, PedId, Female_PedId = `Female PedId`, Male_PedId = `Male PedId`) %>%
mutate(Male_PedId = ifelse(Male_PedId == 0, Female_PedId, Male_PedId)) %>%
distinct()
# Create lookup for Pedigree to PedId
lookup <- data %>% select(Pedigree, PedId)
# Join and reshape
data_updated <- data %>%
left_join(lookup, by = c("Female_PedId" = "PedId"), suffix = c("", "_female")) %>%
left_join(lookup, by = c("Male_PedId" = "PedId"), suffix = c("", "_male")) %>%
transmute(id = Pedigree, parent1 = Pedigree_female, parent2 = Pedigree_male) %>%
distinct()
return(data_updated)
}
read_data_optimized <- function(geno.file, kinship.file, ploidy, sex=NULL,
matings="none", standardize=FALSE,
n.core=4, partition=FALSE, chunk_size=100000, result_file="matings_results.csv") {
# Helper function to calculate MPH (mid-parent heterosis)
MPH <- function(parents, ploidy, geno) {
Xi <- geno[,parents[1]]
Xj <- geno[,parents[2]]
ploidy/4/(ploidy-1)*((Xi-Xj)^2 + 2/ploidy*Xi*Xj - (Xi+Xj))
}
# Function to process each chunk in parallel
process_chunk_parallel <- function(matings_chunk, ploidy, geno, effects, n.core) {
mate.list <- split(as.matrix(matings_chunk[, 1:2]), f=1:nrow(matings_chunk))
cl <- makeCluster(n.core)
# Export necessary variables to worker nodes
clusterExport(cl, varlist=c("MPH", "ploidy", "geno", "effects"), envir=environment())
# Run the parallel calculation
ans <- parSapply(cl, mate.list, MPH, ploidy=ploidy, geno=geno)
stopCluster(cl)
return(ans)
}
# Load geno data and kinship matrix using read.csv due to input format constraints
data <- read.csv(file = geno.file, check.names=FALSE, row.names=1)
dominance <- (colnames(data)[2] == "dom")
geno.start <- 2 + as.integer(dominance)
effects <- as.matrix(data[,1:(geno.start-1), drop=FALSE])
geno <- as.matrix(data[,geno.start:ncol(data)])
p <- apply(geno, 1, mean, na.rm=TRUE) / ploidy
rownames(geno) <- rownames(data)
id <- colnames(geno)
Pmat <- kronecker(matrix(p, nrow=1, ncol=nrow(geno)), matrix(1, nrow=ncol(geno), ncol=1))
coeff <- t(geno) - ploidy * Pmat
dimnames(coeff) <- list(id, rownames(geno))
coeff[is.na(coeff)] <- 0
# Load kinship matrix
K <- as.matrix(read.csv(kinship.file, row.names=1, check.names=FALSE))
K <- K[id, id]
parents <- data.frame(id=id, add=as.numeric(coeff %*% effects[,1,drop=FALSE]))
if (dominance) {
coeff.D <- -2*choose(ploidy,2)*Pmat^2 + 2*(ploidy-1)*Pmat*t(geno) - t(geno)*(t(geno)-1)
coeff.D[is.na(coeff.D)] <- 0
gamma <- (ploidy/2 - 1)/(ploidy - 1)
parents$dom <- as.numeric(coeff.D %*% effects[,2,drop=FALSE])
parents$merit <- parents$add + gamma*parents$dom
} else {
parents$merit <- parents$add
}
sd.merit <- sd(parents$add)
if (standardize)
parents$merit <- parents$merit/sd.merit
if (!is.null(sex)) {
colnames(sex) <- c("id", "female")
parents <- merge(parents, sex)
}
# Handle 'matings' parameter
if (is.character(matings) && length(matings) == 1 && matings == "none") {
return(list(K=K, parents=parents[, setdiff(colnames(parents), c("add", "dom"))]))
} else if (is.character(matings) && length(matings) == 1 && matings == "all") {
matings <- parents$id
}
if ("female" %in% colnames(parents)) {
females <- intersect(parents$id[parents$female], matings)
males <- intersect(parents$id[!parents$female], matings)
matings <- data.frame(expand.grid(female=females, male=males, stringsAsFactors=FALSE))
} else {
id2 <- intersect(matings, parents$id)
matings <- data.frame(expand.grid(female=id2, male=id2, stringsAsFactors=FALSE))
matings <- matings[matings$female >= matings$male,]
}
matings$female <- as.character(matings$female)
matings$male <- as.character(matings$male)
# Initialize result file with an empty data frame
empty_df <- data.table(female=character(), male=character(), merit=numeric())
if (dominance) {
empty_df[, `:=` (MPA=numeric(), MPD=numeric(), MPH=numeric())]
}
# Write the empty data frame to initialize the result file
fwrite(empty_df, file=result_file)
# Process matings in chunks
for (i in seq(1, nrow(matings), by=chunk_size)) {
mating_chunk <- matings[i:min(i + chunk_size - 1, nrow(matings)), ]
mating_chunk$merit <- (parents$add[match(mating_chunk$female, parents$id)] +
parents$add[match(mating_chunk$male, parents$id)])/2
if (dominance) {
mating_chunk$MPA <- mating_chunk$merit
mating_chunk$MPD <- (parents$dom[match(mating_chunk$female, parents$id)] +
parents$dom[match(mating_chunk$male, parents$id)])/2
# Parallel merit calculation
ans <- process_chunk_parallel(mating_chunk, ploidy, geno, effects, n.core)
mating_chunk$MPH <- as.numeric(crossprod(ans, effects[,2]))
if (standardize) {
mating_chunk$MPA <- mating_chunk$MPA / sd.merit
mating_chunk$MPD <- mating_chunk$MPD / sd.merit
mating_chunk$MPH <- mating_chunk$MPH / sd.merit
}
mating_chunk$merit <- mating_chunk$MPA + mating_chunk$MPD + mating_chunk$MPH
} else if (standardize) {
mating_chunk$merit <- mating_chunk$merit / sd.merit
}
# Append chunk results to the file
fwrite(mating_chunk, file=result_file, append=TRUE)
}
# Read and Format Matings
matings = fread(result_file, select = c("female", "male", "merit"))
colnames(matings) = c("parent1", "parent2", "merit")
# Return parents, K matrix, and matings
return(list(K=K, parents=parents[, setdiff(colnames(parents), c("add", "dom"))], matings=matings))
}
oma_reduced = function(dF = c(0.01,0.01), geno.file, kinship.file, ploidy = 2, selection.intensity = 0.10, solver="ECOS", dF.adapt = list(step = 0.005, max = 1)) {
stopifnot(length(dF) == 2L)
stopifnot(dF[1] <= dF[2])
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = "all",
standardize = TRUE)
max.parent = ceiling(as.numeric(length(ans1$parents$id)) * selection.intensity)
ans2 = COMA::ocs(parents = data.frame(ans1$parents, min = 0, max = 1/max.parent),
ploidy = ploidy,
K = ans1$K,
dF = dF[2],
dF.adapt = dF.adapt,
solver = solver)
if (nrow(ans2$oc) == 0) {
stop("No solution possible.")
}
sel1 = ans2$oc$id[order(ans2$oc$value, decreasing = T)]
if (length(sel1) > max.parent)
sel1 = sel1[1:max.parent]
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = sel1,
standardize = TRUE)
ans3 = COMA::oma(parents = data.frame(id = sel1, min = 0, max = 1),
matings = data.frame(ans1$matings, min = 0, max = 1),
ploidy = ploidy,
K = ans1$K,
dF = dF,
dF.adapt = dF.adapt,
solver = solver)
if (nrow(ans3$om) == 0) {
stop("No solution possible.")
}
return(ans3)
}
save.image(file = "Functions.RData")
getwd()
load("~/Documents/John_Early100_GBLUPs/Testing/OCS_OMA_Testing.RData")
load("~/Documents/John_Early100_GBLUPs/Testing/OCS_OMA_Testing.RData")
oma_reduced = function(dF = c(0.01,0.01), geno.file, kinship.file, ploidy = 2, selection.intensity = 1, solver="ECOS", dF.adapt = list(step = 0.005, max = 1), base = "RM") {
stopifnot(length(dF) == 2L)
stopifnot(dF[1] <= dF[2])
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = "all",
standardize = TRUE)
max.parent = ceiling(as.numeric(length(ans1$parents$id)) * selection.intensity)
ans2 = COMA::ocs(parents = data.frame(ans1$parents, min = 0, max = 1/max.parent),
ploidy = ploidy,
K = ans1$K,
dF = dF[2],
dF.adapt = dF.adapt,
solver = solver,
base = base)
if (nrow(ans2$oc) == 0) {
stop("No solution possible.")
}
sel1 = ans2$oc$id[order(ans2$oc$value, decreasing = T)]
if (length(sel1) > max.parent)
sel1 = sel1[1:max.parent]
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = sel1,
standardize = TRUE)
ans3 = COMA::oma(parents = data.frame(id = sel1, min = 0, max = 1),
matings = data.frame(ans1$matings, min = 0, max = 1),
ploidy = ploidy,
K = ans1$K,
dF = dF,
dF.adapt = dF.adapt,
solver = solver,
base = base)
if (nrow(ans3$om) == 0) {
stop("No solution possible.")
}
return(ans3)
}
oma_reduced = function(dF = c(0.01,0.01), geno.file, kinship.file, ploidy = 2, selection.intensity = 0.10, solver="ECOS", dF.adapt = list(step = 0.005, max = 1), base = "RM") {
stopifnot(length(dF) == 2L)
stopifnot(dF[1] <= dF[2])
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = "all",
standardize = TRUE)
max.parent = ceiling(as.numeric(length(ans1$parents$id)) * selection.intensity)
ans2 = COMA::ocs(parents = data.frame(ans1$parents, min = 0, max = 1/max.parent),
ploidy = ploidy,
K = ans1$K,
dF = dF[2],
dF.adapt = dF.adapt,
solver = solver,
base = base)
if (nrow(ans2$oc) == 0) {
stop("No solution possible.")
}
sel1 = ans2$oc$id[order(ans2$oc$value, decreasing = T)]
if (length(sel1) > max.parent)
sel1 = sel1[1:max.parent]
ans1 = read_data_optimized(geno.file = geno.file,
kinship.file = kinship.file,
ploidy = ploidy,
matings = sel1,
standardize = TRUE)
ans3 = COMA::oma(parents = data.frame(id = sel1, min = 0, max = 1),
matings = data.frame(ans1$matings, min = 0, max = 1),
ploidy = ploidy,
K = ans1$K,
dF = dF,
dF.adapt = dF.adapt,
solver = solver,
base = base)
if (nrow(ans3$om) == 0) {
stop("No solution possible.")
}
return(ans3)
}
library(data.table)
library(dplyr)
library(tidyr)
library(janitor)
library(asreml)
library(StageWise)
library(future)
library(future.apply)
library(COMA)
library(AGHmatrix)
library(parallel)
library(CVXR)
geno.file = "~/Documents/John_Early100_GBLUPs/Testing/COMA_file_1.csv"
kinship.file = "~/Documents/John_Early100_GBLUPs/Testing/COMA_file_2.csv"
# dF = c(0.01,0.01) and dF.adapt = list(step = 0.005, max = 0.1)
result = oma_reduced(geno.file = geno.file, kinship.file = kinship.file, dF.adapt = list(step = 0.005, max = 0.1))
rm(result2, result3)
save.image(file = "OCS_OMA_Testing.RData")
crosses = result$om[!result$om$parent1 == result$om$parent2,]
View(crosses)
?oma
2000/15
crosses$induction = ceiling(crosses$value*induction.rows)
induction.rows = 150
crosses$induction = ceiling(crosses$value*induction.rows)
crosses = result$om[!result$om$parent1 == result$om$parent2,]
crosses = crosses[order(crosses$value, decreasing = T)]
crosses = crosses[order(crosses$value, decreasing = T),]
induction.rows = 150
crosses$induction = ceiling(crosses$value*induction.rows)
induction.rows = 150
crosses$induction = ceiling(crosses$value*induction.rows)
for (i in 1:nrow(crosses)) {
temp = crosses[1:i,]
if (sum(temp$induction) < induction.rows) {
i = i + 1
} else {
return(temp)
}
}
View(temp)
sum(temp$induction)
rm(temp)
induction.rows = 150
crosses$induction = ceiling(crosses$value*induction.rows)
for (i in 1:nrow(crosses)) {
temp = crosses[1:i,]
if (sum(temp$induction) < induction.rows) {
i = i + 1
} else {
crosses = temp
return(crosses)
}
}
View(crosses)
nursery_constraints = function(df, nursery.rows) {
df = df
df$nursery = ceiling(df$value*nursery.rows)
for (i in 1:nrow(df)) {
temp = df[1:i,]
if (sum(temp$nursery) < nursery.rows) {
i = i + 1
} else {
df = temp
return(df)
}
}
}
crosses = result$om[!result$om$parent1 == result$om$parent2,]
crosses = crosses[order(crosses$value, decreasing = T),]
crosses = nursery_constraints(df = crosses, nursery.rows = 150)
View(crosses)
rm(temp)
rm(induction.rows)
save.image(file = "OCS_OMA_Testing.RData")
View(crosses)
43560/2.5
9467-9240
227/10000
40/56*43560/(22.5*2.5*2)
25.74-(25.74*0.145)
setwd("~/Documents/BreedStream")
install.packages("usethis")
library(usethis)
create_package(".")
library(roxygen2)
roxygen2::roxygenise()
devtools::build()
devtools::install()
library(BreedStream)
## install if needed (do this exactly once):
## install.packages("usethis")
library(usethis)
use_git_config(user.name = "JohnSearl007", user.email = "jsearl007@gmail.com")
